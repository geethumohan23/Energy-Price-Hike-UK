{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5cb8a81",
   "metadata": {},
   "source": [
    "# Decision Tree Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5793f7",
   "metadata": {},
   "source": [
    "# PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95cf5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries to smoothly carry out the operations\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from matplotlib import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c64aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read data from local storage\n",
    "P2_Data = pd.read_csv('P2\\CE802_P2_Data.csv', dayfirst=True)\n",
    "Data=P2_Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcecfcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-28749.730710</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>-5.008527</td>\n",
       "      <td>-7.073618</td>\n",
       "      <td>1787.391510</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>4.314597</td>\n",
       "      <td>16794.708266</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>-10014.212102</td>\n",
       "      <td>...</td>\n",
       "      <td>39.155125</td>\n",
       "      <td>-13.932299</td>\n",
       "      <td>6.097217</td>\n",
       "      <td>15.932875</td>\n",
       "      <td>4.033075</td>\n",
       "      <td>9994.592611</td>\n",
       "      <td>-3750.649178</td>\n",
       "      <td>3.255798</td>\n",
       "      <td>-5066.909169</td>\n",
       "      <td>-10.183520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1688.229804</td>\n",
       "      <td>0.499408</td>\n",
       "      <td>1.343875</td>\n",
       "      <td>2.708288</td>\n",
       "      <td>702.890861</td>\n",
       "      <td>0.500201</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>2074.355688</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>1494.941683</td>\n",
       "      <td>...</td>\n",
       "      <td>14.584924</td>\n",
       "      <td>10.285697</td>\n",
       "      <td>1.802407</td>\n",
       "      <td>2.708330</td>\n",
       "      <td>2.609035</td>\n",
       "      <td>1058.036210</td>\n",
       "      <td>739.616151</td>\n",
       "      <td>2.699756</td>\n",
       "      <td>1023.164795</td>\n",
       "      <td>1.062748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-81470.290000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>-15.676000</td>\n",
       "      <td>-17.676000</td>\n",
       "      <td>-1942.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.540592</td>\n",
       "      <td>7679.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19975.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.360000</td>\n",
       "      <td>-85.560000</td>\n",
       "      <td>4.225980</td>\n",
       "      <td>12.966360</td>\n",
       "      <td>1.266660</td>\n",
       "      <td>3700.240000</td>\n",
       "      <td>-8521.050000</td>\n",
       "      <td>0.334140</td>\n",
       "      <td>-12915.220000</td>\n",
       "      <td>-13.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-28720.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>-5.319050</td>\n",
       "      <td>-8.262750</td>\n",
       "      <td>1506.272500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.827700</td>\n",
       "      <td>15994.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10175.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>29.930250</td>\n",
       "      <td>-16.732500</td>\n",
       "      <td>4.743650</td>\n",
       "      <td>13.852350</td>\n",
       "      <td>2.079975</td>\n",
       "      <td>9584.540000</td>\n",
       "      <td>-3791.062500</td>\n",
       "      <td>1.150725</td>\n",
       "      <td>-5335.020000</td>\n",
       "      <td>-10.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-28701.070500</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.507200</td>\n",
       "      <td>-6.221100</td>\n",
       "      <td>1649.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.180750</td>\n",
       "      <td>16381.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9636.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>39.270150</td>\n",
       "      <td>-10.862000</td>\n",
       "      <td>5.534500</td>\n",
       "      <td>15.096750</td>\n",
       "      <td>3.267150</td>\n",
       "      <td>9755.930000</td>\n",
       "      <td>-3589.140000</td>\n",
       "      <td>2.384400</td>\n",
       "      <td>-5044.997000</td>\n",
       "      <td>-10.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-28682.255000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.127370</td>\n",
       "      <td>-5.059425</td>\n",
       "      <td>1880.725000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.694500</td>\n",
       "      <td>17021.730000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9383.513500</td>\n",
       "      <td>...</td>\n",
       "      <td>48.359250</td>\n",
       "      <td>-6.972000</td>\n",
       "      <td>6.834000</td>\n",
       "      <td>17.170500</td>\n",
       "      <td>5.188500</td>\n",
       "      <td>10066.240000</td>\n",
       "      <td>-3489.926250</td>\n",
       "      <td>4.704750</td>\n",
       "      <td>-4795.820000</td>\n",
       "      <td>-9.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-24983.290000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.040002</td>\n",
       "      <td>-4.206600</td>\n",
       "      <td>6602.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.081000</td>\n",
       "      <td>32339.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1929.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>86.280000</td>\n",
       "      <td>-3.782328</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>26.424000</td>\n",
       "      <td>14.805000</td>\n",
       "      <td>21124.240000</td>\n",
       "      <td>1171.950000</td>\n",
       "      <td>13.536000</td>\n",
       "      <td>1892.780000</td>\n",
       "      <td>-6.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1           F2           F3           F4           F5  \\\n",
       "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean  -28749.730710     1.259000    -5.008527    -7.073618  1787.391510   \n",
       "std     1688.229804     0.499408     1.343875     2.708288   702.890861   \n",
       "min   -81470.290000     0.730000   -15.676000   -17.676000 -1942.650000   \n",
       "25%   -28720.400000     0.730000    -5.319050    -8.262750  1506.272500   \n",
       "50%   -28701.070500     1.730000    -4.507200    -6.221100  1649.040000   \n",
       "75%   -28682.255000     1.730000    -4.127370    -5.059425  1880.725000   \n",
       "max   -24983.290000     1.730000    -4.040002    -4.206600  6602.350000   \n",
       "\n",
       "                F6           F7            F8           F9           F10  ...  \\\n",
       "count  1000.000000  1000.000000   1000.000000  1000.000000   1000.000000  ...   \n",
       "mean      0.507000     4.314597  16794.708266     0.481000 -10014.212102  ...   \n",
       "std       0.500201     0.614178   2074.355688     0.499889   1494.941683  ...   \n",
       "min       0.000000     3.540592   7679.980000     0.000000 -19975.820000  ...   \n",
       "25%       0.000000     3.827700  15994.420000     0.000000 -10175.920000  ...   \n",
       "50%       1.000000     4.180750  16381.580000     0.000000  -9636.920000  ...   \n",
       "75%       1.000000     4.694500  17021.730000     1.000000  -9383.513500  ...   \n",
       "max       1.000000     7.081000  32339.980000     1.000000  -1929.820000  ...   \n",
       "\n",
       "               F12          F13          F14          F15          F16  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean     39.155125   -13.932299     6.097217    15.932875     4.033075   \n",
       "std      14.584924    10.285697     1.802407     2.708330     2.609035   \n",
       "min     -18.360000   -85.560000     4.225980    12.966360     1.266660   \n",
       "25%      29.930250   -16.732500     4.743650    13.852350     2.079975   \n",
       "50%      39.270150   -10.862000     5.534500    15.096750     3.267150   \n",
       "75%      48.359250    -6.972000     6.834000    17.170500     5.188500   \n",
       "max      86.280000    -3.782328    13.330000    26.424000    14.805000   \n",
       "\n",
       "                F17          F18          F19           F20         F21  \n",
       "count   1000.000000  1000.000000  1000.000000   1000.000000  500.000000  \n",
       "mean    9994.592611 -3750.649178     3.255798  -5066.909169  -10.183520  \n",
       "std     1058.036210   739.616151     2.699756   1023.164795    1.062748  \n",
       "min     3700.240000 -8521.050000     0.334140 -12915.220000  -13.620000  \n",
       "25%     9584.540000 -3791.062500     1.150725  -5335.020000  -10.925000  \n",
       "50%     9755.930000 -3589.140000     2.384400  -5044.997000  -10.135000  \n",
       "75%    10066.240000 -3489.926250     4.704750  -4795.820000   -9.450000  \n",
       "max    21124.240000  1171.950000    13.536000   1892.780000   -6.810000  \n",
       "\n",
       "[8 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the data for better understanding\n",
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19332dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "#sns.pairplot(Data,hue='Class',size=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e4b6785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1       float64\n",
       "F2       float64\n",
       "F3       float64\n",
       "F4       float64\n",
       "F5       float64\n",
       "F6         int64\n",
       "F7       float64\n",
       "F8       float64\n",
       "F9         int64\n",
       "F10      float64\n",
       "F11      float64\n",
       "F12      float64\n",
       "F13      float64\n",
       "F14      float64\n",
       "F15      float64\n",
       "F16      float64\n",
       "F17      float64\n",
       "F18      float64\n",
       "F19      float64\n",
       "F20      float64\n",
       "F21      float64\n",
       "Class       bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Detailed study on data types\n",
    "Data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5cffd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28703.964</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.051752</td>\n",
       "      <td>-6.99630</td>\n",
       "      <td>1473.45</td>\n",
       "      <td>0</td>\n",
       "      <td>4.40510</td>\n",
       "      <td>16004.16</td>\n",
       "      <td>1</td>\n",
       "      <td>-11645.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.7350</td>\n",
       "      <td>5.9854</td>\n",
       "      <td>14.24730</td>\n",
       "      <td>1.4892</td>\n",
       "      <td>9959.04</td>\n",
       "      <td>-3199.350</td>\n",
       "      <td>6.8670</td>\n",
       "      <td>-4850.820</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28726.730</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-5.153000</td>\n",
       "      <td>-4.27404</td>\n",
       "      <td>783.15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54500</td>\n",
       "      <td>16041.48</td>\n",
       "      <td>1</td>\n",
       "      <td>-9759.420</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.1710</td>\n",
       "      <td>4.6222</td>\n",
       "      <td>14.99820</td>\n",
       "      <td>3.1206</td>\n",
       "      <td>10107.44</td>\n",
       "      <td>-3064.950</td>\n",
       "      <td>9.4710</td>\n",
       "      <td>378.780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-28717.120</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-8.440000</td>\n",
       "      <td>-8.25900</td>\n",
       "      <td>2573.95</td>\n",
       "      <td>0</td>\n",
       "      <td>3.59962</td>\n",
       "      <td>16422.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-10775.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.6500</td>\n",
       "      <td>4.4096</td>\n",
       "      <td>17.79000</td>\n",
       "      <td>1.9818</td>\n",
       "      <td>10971.04</td>\n",
       "      <td>-3638.850</td>\n",
       "      <td>2.0373</td>\n",
       "      <td>-5215.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-81470.290</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.386600</td>\n",
       "      <td>-5.57460</td>\n",
       "      <td>1499.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3.56675</td>\n",
       "      <td>16270.04</td>\n",
       "      <td>1</td>\n",
       "      <td>-9416.714</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.6390</td>\n",
       "      <td>8.5080</td>\n",
       "      <td>12.98424</td>\n",
       "      <td>11.5620</td>\n",
       "      <td>9681.10</td>\n",
       "      <td>724.950</td>\n",
       "      <td>2.0220</td>\n",
       "      <td>-4378.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-28750.800</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.650200</td>\n",
       "      <td>-4.33848</td>\n",
       "      <td>1409.15</td>\n",
       "      <td>1</td>\n",
       "      <td>5.07000</td>\n",
       "      <td>16548.78</td>\n",
       "      <td>1</td>\n",
       "      <td>-9797.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.7300</td>\n",
       "      <td>5.5188</td>\n",
       "      <td>13.57260</td>\n",
       "      <td>2.5440</td>\n",
       "      <td>10965.64</td>\n",
       "      <td>-2607.150</td>\n",
       "      <td>4.3140</td>\n",
       "      <td>-1919.220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-28685.380</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.095060</td>\n",
       "      <td>-15.54300</td>\n",
       "      <td>1654.77</td>\n",
       "      <td>1</td>\n",
       "      <td>4.09930</td>\n",
       "      <td>16381.38</td>\n",
       "      <td>0</td>\n",
       "      <td>-9861.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.3800</td>\n",
       "      <td>6.4440</td>\n",
       "      <td>13.15350</td>\n",
       "      <td>3.2538</td>\n",
       "      <td>10170.64</td>\n",
       "      <td>-3932.850</td>\n",
       "      <td>1.4196</td>\n",
       "      <td>-5053.546</td>\n",
       "      <td>-10.75</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-28668.770</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.050914</td>\n",
       "      <td>-9.18600</td>\n",
       "      <td>1457.85</td>\n",
       "      <td>0</td>\n",
       "      <td>4.36770</td>\n",
       "      <td>16036.38</td>\n",
       "      <td>0</td>\n",
       "      <td>-9418.336</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.7600</td>\n",
       "      <td>4.7966</td>\n",
       "      <td>14.72040</td>\n",
       "      <td>13.4190</td>\n",
       "      <td>9607.28</td>\n",
       "      <td>-3421.860</td>\n",
       "      <td>1.6728</td>\n",
       "      <td>-4964.700</td>\n",
       "      <td>-10.35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-28667.610</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.887000</td>\n",
       "      <td>-11.41200</td>\n",
       "      <td>1515.96</td>\n",
       "      <td>0</td>\n",
       "      <td>5.01500</td>\n",
       "      <td>16097.92</td>\n",
       "      <td>1</td>\n",
       "      <td>-10209.620</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.6400</td>\n",
       "      <td>6.4060</td>\n",
       "      <td>13.55100</td>\n",
       "      <td>2.1246</td>\n",
       "      <td>10907.64</td>\n",
       "      <td>-2875.950</td>\n",
       "      <td>2.6988</td>\n",
       "      <td>-4965.880</td>\n",
       "      <td>-11.01</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-28750.050</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-5.490800</td>\n",
       "      <td>-5.07480</td>\n",
       "      <td>2249.25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.88900</td>\n",
       "      <td>16120.46</td>\n",
       "      <td>1</td>\n",
       "      <td>-9358.160</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.4210</td>\n",
       "      <td>4.5810</td>\n",
       "      <td>16.77000</td>\n",
       "      <td>4.0221</td>\n",
       "      <td>9815.54</td>\n",
       "      <td>-3513.039</td>\n",
       "      <td>6.1860</td>\n",
       "      <td>-4261.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-28700.553</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.040009</td>\n",
       "      <td>-5.74200</td>\n",
       "      <td>1752.85</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76460</td>\n",
       "      <td>16476.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-9690.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.3329</td>\n",
       "      <td>4.4034</td>\n",
       "      <td>15.71520</td>\n",
       "      <td>1.6698</td>\n",
       "      <td>9407.24</td>\n",
       "      <td>-3576.120</td>\n",
       "      <td>2.5524</td>\n",
       "      <td>-5019.800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1    F2        F3        F4       F5  F6       F7        F8  F9  \\\n",
       "0   -28703.964  0.73 -4.051752  -6.99630  1473.45   0  4.40510  16004.16   1   \n",
       "1   -28726.730  1.73 -5.153000  -4.27404   783.15   0  4.54500  16041.48   1   \n",
       "2   -28717.120  0.73 -8.440000  -8.25900  2573.95   0  3.59962  16422.78   0   \n",
       "3   -81470.290  0.73 -4.386600  -5.57460  1499.68   0  3.56675  16270.04   1   \n",
       "4   -28750.800  1.73 -4.650200  -4.33848  1409.15   1  5.07000  16548.78   1   \n",
       "..         ...   ...       ...       ...      ...  ..      ...       ...  ..   \n",
       "995 -28685.380  0.73 -4.095060 -15.54300  1654.77   1  4.09930  16381.38   0   \n",
       "996 -28668.770  1.73 -4.050914  -9.18600  1457.85   0  4.36770  16036.38   0   \n",
       "997 -28667.610  1.73 -4.887000 -11.41200  1515.96   0  5.01500  16097.92   1   \n",
       "998 -28750.050  0.73 -5.490800  -5.07480  2249.25   0  3.88900  16120.46   1   \n",
       "999 -28700.553  1.73 -4.040009  -5.74200  1752.85   1  3.76460  16476.78   0   \n",
       "\n",
       "           F10  ...      F13     F14       F15      F16       F17       F18  \\\n",
       "0   -11645.820  ... -13.7350  5.9854  14.24730   1.4892   9959.04 -3199.350   \n",
       "1    -9759.420  ...  -5.1710  4.6222  14.99820   3.1206  10107.44 -3064.950   \n",
       "2   -10775.220  ... -38.6500  4.4096  17.79000   1.9818  10971.04 -3638.850   \n",
       "3    -9416.714  ...  -8.6390  8.5080  12.98424  11.5620   9681.10   724.950   \n",
       "4    -9797.820  ... -14.7300  5.5188  13.57260   2.5440  10965.64 -2607.150   \n",
       "..         ...  ...      ...     ...       ...      ...       ...       ...   \n",
       "995  -9861.820  ... -19.3800  6.4440  13.15350   3.2538  10170.64 -3932.850   \n",
       "996  -9418.336  ... -31.7600  4.7966  14.72040  13.4190   9607.28 -3421.860   \n",
       "997 -10209.620  ... -19.6400  6.4060  13.55100   2.1246  10907.64 -2875.950   \n",
       "998  -9358.160  ...  -6.4210  4.5810  16.77000   4.0221   9815.54 -3513.039   \n",
       "999  -9690.220  ...  -4.3329  4.4034  15.71520   1.6698   9407.24 -3576.120   \n",
       "\n",
       "        F19       F20    F21  Class  \n",
       "0    6.8670 -4850.820    NaN  False  \n",
       "1    9.4710   378.780    NaN   True  \n",
       "2    2.0373 -5215.480    NaN  False  \n",
       "3    2.0220 -4378.420    NaN  False  \n",
       "4    4.3140 -1919.220    NaN   True  \n",
       "..      ...       ...    ...    ...  \n",
       "995  1.4196 -5053.546 -10.75  False  \n",
       "996  1.6728 -4964.700 -10.35  False  \n",
       "997  2.6988 -4965.880 -11.01   True  \n",
       "998  6.1860 -4261.020    NaN  False  \n",
       "999  2.5524 -5019.800    NaN  False  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Study the data and strucure to proceed further\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d418379",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualising data to understand the missing values\n",
    "import missingno as msno\n",
    "%matplotlib inline\n",
    "#msno.heatmap(Data)\n",
    "msno.bar(Data, color=\"dodgerblue\", sort=\"ascending\", figsize=(10,5), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d805231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-28749.730710</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>-5.008527</td>\n",
       "      <td>-7.073618</td>\n",
       "      <td>1787.391510</td>\n",
       "      <td>0.507000</td>\n",
       "      <td>4.314597</td>\n",
       "      <td>16794.708266</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>-10014.212102</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.932299</td>\n",
       "      <td>6.097217</td>\n",
       "      <td>15.932875</td>\n",
       "      <td>4.033075</td>\n",
       "      <td>9994.592611</td>\n",
       "      <td>-3750.649178</td>\n",
       "      <td>3.255798</td>\n",
       "      <td>-5066.909169</td>\n",
       "      <td>-10.183520</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1688.229804</td>\n",
       "      <td>0.499408</td>\n",
       "      <td>1.343875</td>\n",
       "      <td>2.708288</td>\n",
       "      <td>702.890861</td>\n",
       "      <td>0.500201</td>\n",
       "      <td>0.614178</td>\n",
       "      <td>2074.355688</td>\n",
       "      <td>0.499889</td>\n",
       "      <td>1494.941683</td>\n",
       "      <td>...</td>\n",
       "      <td>10.285697</td>\n",
       "      <td>1.802407</td>\n",
       "      <td>2.708330</td>\n",
       "      <td>2.609035</td>\n",
       "      <td>1058.036210</td>\n",
       "      <td>739.616151</td>\n",
       "      <td>2.699756</td>\n",
       "      <td>1023.164795</td>\n",
       "      <td>1.062748</td>\n",
       "      <td>0.500214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-81470.290000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>-15.676000</td>\n",
       "      <td>-17.676000</td>\n",
       "      <td>-1942.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.540592</td>\n",
       "      <td>7679.980000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-19975.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>-85.560000</td>\n",
       "      <td>4.225980</td>\n",
       "      <td>12.966360</td>\n",
       "      <td>1.266660</td>\n",
       "      <td>3700.240000</td>\n",
       "      <td>-8521.050000</td>\n",
       "      <td>0.334140</td>\n",
       "      <td>-12915.220000</td>\n",
       "      <td>-13.620000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-28720.400000</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>-5.319050</td>\n",
       "      <td>-8.262750</td>\n",
       "      <td>1506.272500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.827700</td>\n",
       "      <td>15994.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10175.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.732500</td>\n",
       "      <td>4.743650</td>\n",
       "      <td>13.852350</td>\n",
       "      <td>2.079975</td>\n",
       "      <td>9584.540000</td>\n",
       "      <td>-3791.062500</td>\n",
       "      <td>1.150725</td>\n",
       "      <td>-5335.020000</td>\n",
       "      <td>-10.925000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-28701.070500</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.507200</td>\n",
       "      <td>-6.221100</td>\n",
       "      <td>1649.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.180750</td>\n",
       "      <td>16381.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9636.920000</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.862000</td>\n",
       "      <td>5.534500</td>\n",
       "      <td>15.096750</td>\n",
       "      <td>3.267150</td>\n",
       "      <td>9755.930000</td>\n",
       "      <td>-3589.140000</td>\n",
       "      <td>2.384400</td>\n",
       "      <td>-5044.997000</td>\n",
       "      <td>-10.135000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-28682.255000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.127370</td>\n",
       "      <td>-5.059425</td>\n",
       "      <td>1880.725000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.694500</td>\n",
       "      <td>17021.730000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9383.513500</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.972000</td>\n",
       "      <td>6.834000</td>\n",
       "      <td>17.170500</td>\n",
       "      <td>5.188500</td>\n",
       "      <td>10066.240000</td>\n",
       "      <td>-3489.926250</td>\n",
       "      <td>4.704750</td>\n",
       "      <td>-4795.820000</td>\n",
       "      <td>-9.450000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>-24983.290000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>-4.040002</td>\n",
       "      <td>-4.206600</td>\n",
       "      <td>6602.350000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.081000</td>\n",
       "      <td>32339.980000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1929.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.782328</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>26.424000</td>\n",
       "      <td>14.805000</td>\n",
       "      <td>21124.240000</td>\n",
       "      <td>1171.950000</td>\n",
       "      <td>13.536000</td>\n",
       "      <td>1892.780000</td>\n",
       "      <td>-6.810000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 F1           F2           F3           F4           F5  \\\n",
       "count   1000.000000  1000.000000  1000.000000  1000.000000  1000.000000   \n",
       "mean  -28749.730710     1.259000    -5.008527    -7.073618  1787.391510   \n",
       "std     1688.229804     0.499408     1.343875     2.708288   702.890861   \n",
       "min   -81470.290000     0.730000   -15.676000   -17.676000 -1942.650000   \n",
       "25%   -28720.400000     0.730000    -5.319050    -8.262750  1506.272500   \n",
       "50%   -28701.070500     1.730000    -4.507200    -6.221100  1649.040000   \n",
       "75%   -28682.255000     1.730000    -4.127370    -5.059425  1880.725000   \n",
       "max   -24983.290000     1.730000    -4.040002    -4.206600  6602.350000   \n",
       "\n",
       "                F6           F7            F8           F9           F10  ...  \\\n",
       "count  1000.000000  1000.000000   1000.000000  1000.000000   1000.000000  ...   \n",
       "mean      0.507000     4.314597  16794.708266     0.481000 -10014.212102  ...   \n",
       "std       0.500201     0.614178   2074.355688     0.499889   1494.941683  ...   \n",
       "min       0.000000     3.540592   7679.980000     0.000000 -19975.820000  ...   \n",
       "25%       0.000000     3.827700  15994.420000     0.000000 -10175.920000  ...   \n",
       "50%       1.000000     4.180750  16381.580000     0.000000  -9636.920000  ...   \n",
       "75%       1.000000     4.694500  17021.730000     1.000000  -9383.513500  ...   \n",
       "max       1.000000     7.081000  32339.980000     1.000000  -1929.820000  ...   \n",
       "\n",
       "               F13          F14          F15          F16           F17  \\\n",
       "count  1000.000000  1000.000000  1000.000000  1000.000000   1000.000000   \n",
       "mean    -13.932299     6.097217    15.932875     4.033075   9994.592611   \n",
       "std      10.285697     1.802407     2.708330     2.609035   1058.036210   \n",
       "min     -85.560000     4.225980    12.966360     1.266660   3700.240000   \n",
       "25%     -16.732500     4.743650    13.852350     2.079975   9584.540000   \n",
       "50%     -10.862000     5.534500    15.096750     3.267150   9755.930000   \n",
       "75%      -6.972000     6.834000    17.170500     5.188500  10066.240000   \n",
       "max      -3.782328    13.330000    26.424000    14.805000  21124.240000   \n",
       "\n",
       "               F18          F19           F20         F21        Class  \n",
       "count  1000.000000  1000.000000   1000.000000  500.000000  1000.000000  \n",
       "mean  -3750.649178     3.255798  -5066.909169  -10.183520     0.506000  \n",
       "std     739.616151     2.699756   1023.164795    1.062748     0.500214  \n",
       "min   -8521.050000     0.334140 -12915.220000  -13.620000     0.000000  \n",
       "25%   -3791.062500     1.150725  -5335.020000  -10.925000     0.000000  \n",
       "50%   -3589.140000     2.384400  -5044.997000  -10.135000     1.000000  \n",
       "75%   -3489.926250     4.704750  -4795.820000   -9.450000     1.000000  \n",
       "max    1171.950000    13.536000   1892.780000   -6.810000     1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replacing True and False with 0's and 1's for categorical value conversion through label encoding\n",
    "Data.Class = Data.Class.replace({True: 1, False: 0})\n",
    "Data.isnull().sum()\n",
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "897ee4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of data\n",
    "Data_Mean=Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4480c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values using mean value imputation\n",
    "Data_Mean['F21'].fillna(Data_Mean['F21'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d2f2e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28703.964</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.051752</td>\n",
       "      <td>-6.99630</td>\n",
       "      <td>1473.45</td>\n",
       "      <td>0</td>\n",
       "      <td>4.40510</td>\n",
       "      <td>16004.16</td>\n",
       "      <td>1</td>\n",
       "      <td>-11645.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.7350</td>\n",
       "      <td>5.9854</td>\n",
       "      <td>14.24730</td>\n",
       "      <td>1.4892</td>\n",
       "      <td>9959.04</td>\n",
       "      <td>-3199.350</td>\n",
       "      <td>6.8670</td>\n",
       "      <td>-4850.820</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28726.730</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-5.153000</td>\n",
       "      <td>-4.27404</td>\n",
       "      <td>783.15</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54500</td>\n",
       "      <td>16041.48</td>\n",
       "      <td>1</td>\n",
       "      <td>-9759.420</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.1710</td>\n",
       "      <td>4.6222</td>\n",
       "      <td>14.99820</td>\n",
       "      <td>3.1206</td>\n",
       "      <td>10107.44</td>\n",
       "      <td>-3064.950</td>\n",
       "      <td>9.4710</td>\n",
       "      <td>378.780</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-28717.120</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-8.440000</td>\n",
       "      <td>-8.25900</td>\n",
       "      <td>2573.95</td>\n",
       "      <td>0</td>\n",
       "      <td>3.59962</td>\n",
       "      <td>16422.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-10775.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.6500</td>\n",
       "      <td>4.4096</td>\n",
       "      <td>17.79000</td>\n",
       "      <td>1.9818</td>\n",
       "      <td>10971.04</td>\n",
       "      <td>-3638.850</td>\n",
       "      <td>2.0373</td>\n",
       "      <td>-5215.480</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-81470.290</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.386600</td>\n",
       "      <td>-5.57460</td>\n",
       "      <td>1499.68</td>\n",
       "      <td>0</td>\n",
       "      <td>3.56675</td>\n",
       "      <td>16270.04</td>\n",
       "      <td>1</td>\n",
       "      <td>-9416.714</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.6390</td>\n",
       "      <td>8.5080</td>\n",
       "      <td>12.98424</td>\n",
       "      <td>11.5620</td>\n",
       "      <td>9681.10</td>\n",
       "      <td>724.950</td>\n",
       "      <td>2.0220</td>\n",
       "      <td>-4378.420</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-28750.800</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.650200</td>\n",
       "      <td>-4.33848</td>\n",
       "      <td>1409.15</td>\n",
       "      <td>1</td>\n",
       "      <td>5.07000</td>\n",
       "      <td>16548.78</td>\n",
       "      <td>1</td>\n",
       "      <td>-9797.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.7300</td>\n",
       "      <td>5.5188</td>\n",
       "      <td>13.57260</td>\n",
       "      <td>2.5440</td>\n",
       "      <td>10965.64</td>\n",
       "      <td>-2607.150</td>\n",
       "      <td>4.3140</td>\n",
       "      <td>-1919.220</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-28685.380</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.095060</td>\n",
       "      <td>-15.54300</td>\n",
       "      <td>1654.77</td>\n",
       "      <td>1</td>\n",
       "      <td>4.09930</td>\n",
       "      <td>16381.38</td>\n",
       "      <td>0</td>\n",
       "      <td>-9861.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.3800</td>\n",
       "      <td>6.4440</td>\n",
       "      <td>13.15350</td>\n",
       "      <td>3.2538</td>\n",
       "      <td>10170.64</td>\n",
       "      <td>-3932.850</td>\n",
       "      <td>1.4196</td>\n",
       "      <td>-5053.546</td>\n",
       "      <td>-10.75000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-28668.770</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.050914</td>\n",
       "      <td>-9.18600</td>\n",
       "      <td>1457.85</td>\n",
       "      <td>0</td>\n",
       "      <td>4.36770</td>\n",
       "      <td>16036.38</td>\n",
       "      <td>0</td>\n",
       "      <td>-9418.336</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.7600</td>\n",
       "      <td>4.7966</td>\n",
       "      <td>14.72040</td>\n",
       "      <td>13.4190</td>\n",
       "      <td>9607.28</td>\n",
       "      <td>-3421.860</td>\n",
       "      <td>1.6728</td>\n",
       "      <td>-4964.700</td>\n",
       "      <td>-10.35000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-28667.610</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.887000</td>\n",
       "      <td>-11.41200</td>\n",
       "      <td>1515.96</td>\n",
       "      <td>0</td>\n",
       "      <td>5.01500</td>\n",
       "      <td>16097.92</td>\n",
       "      <td>1</td>\n",
       "      <td>-10209.620</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.6400</td>\n",
       "      <td>6.4060</td>\n",
       "      <td>13.55100</td>\n",
       "      <td>2.1246</td>\n",
       "      <td>10907.64</td>\n",
       "      <td>-2875.950</td>\n",
       "      <td>2.6988</td>\n",
       "      <td>-4965.880</td>\n",
       "      <td>-11.01000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-28750.050</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-5.490800</td>\n",
       "      <td>-5.07480</td>\n",
       "      <td>2249.25</td>\n",
       "      <td>0</td>\n",
       "      <td>3.88900</td>\n",
       "      <td>16120.46</td>\n",
       "      <td>1</td>\n",
       "      <td>-9358.160</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.4210</td>\n",
       "      <td>4.5810</td>\n",
       "      <td>16.77000</td>\n",
       "      <td>4.0221</td>\n",
       "      <td>9815.54</td>\n",
       "      <td>-3513.039</td>\n",
       "      <td>6.1860</td>\n",
       "      <td>-4261.020</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-28700.553</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.040009</td>\n",
       "      <td>-5.74200</td>\n",
       "      <td>1752.85</td>\n",
       "      <td>1</td>\n",
       "      <td>3.76460</td>\n",
       "      <td>16476.78</td>\n",
       "      <td>0</td>\n",
       "      <td>-9690.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.3329</td>\n",
       "      <td>4.4034</td>\n",
       "      <td>15.71520</td>\n",
       "      <td>1.6698</td>\n",
       "      <td>9407.24</td>\n",
       "      <td>-3576.120</td>\n",
       "      <td>2.5524</td>\n",
       "      <td>-5019.800</td>\n",
       "      <td>-10.18352</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1    F2        F3        F4       F5  F6       F7        F8  F9  \\\n",
       "0   -28703.964  0.73 -4.051752  -6.99630  1473.45   0  4.40510  16004.16   1   \n",
       "1   -28726.730  1.73 -5.153000  -4.27404   783.15   0  4.54500  16041.48   1   \n",
       "2   -28717.120  0.73 -8.440000  -8.25900  2573.95   0  3.59962  16422.78   0   \n",
       "3   -81470.290  0.73 -4.386600  -5.57460  1499.68   0  3.56675  16270.04   1   \n",
       "4   -28750.800  1.73 -4.650200  -4.33848  1409.15   1  5.07000  16548.78   1   \n",
       "..         ...   ...       ...       ...      ...  ..      ...       ...  ..   \n",
       "995 -28685.380  0.73 -4.095060 -15.54300  1654.77   1  4.09930  16381.38   0   \n",
       "996 -28668.770  1.73 -4.050914  -9.18600  1457.85   0  4.36770  16036.38   0   \n",
       "997 -28667.610  1.73 -4.887000 -11.41200  1515.96   0  5.01500  16097.92   1   \n",
       "998 -28750.050  0.73 -5.490800  -5.07480  2249.25   0  3.88900  16120.46   1   \n",
       "999 -28700.553  1.73 -4.040009  -5.74200  1752.85   1  3.76460  16476.78   0   \n",
       "\n",
       "           F10  ...      F13     F14       F15      F16       F17       F18  \\\n",
       "0   -11645.820  ... -13.7350  5.9854  14.24730   1.4892   9959.04 -3199.350   \n",
       "1    -9759.420  ...  -5.1710  4.6222  14.99820   3.1206  10107.44 -3064.950   \n",
       "2   -10775.220  ... -38.6500  4.4096  17.79000   1.9818  10971.04 -3638.850   \n",
       "3    -9416.714  ...  -8.6390  8.5080  12.98424  11.5620   9681.10   724.950   \n",
       "4    -9797.820  ... -14.7300  5.5188  13.57260   2.5440  10965.64 -2607.150   \n",
       "..         ...  ...      ...     ...       ...      ...       ...       ...   \n",
       "995  -9861.820  ... -19.3800  6.4440  13.15350   3.2538  10170.64 -3932.850   \n",
       "996  -9418.336  ... -31.7600  4.7966  14.72040  13.4190   9607.28 -3421.860   \n",
       "997 -10209.620  ... -19.6400  6.4060  13.55100   2.1246  10907.64 -2875.950   \n",
       "998  -9358.160  ...  -6.4210  4.5810  16.77000   4.0221   9815.54 -3513.039   \n",
       "999  -9690.220  ...  -4.3329  4.4034  15.71520   1.6698   9407.24 -3576.120   \n",
       "\n",
       "        F19       F20       F21  Class  \n",
       "0    6.8670 -4850.820 -10.18352      0  \n",
       "1    9.4710   378.780 -10.18352      1  \n",
       "2    2.0373 -5215.480 -10.18352      0  \n",
       "3    2.0220 -4378.420 -10.18352      0  \n",
       "4    4.3140 -1919.220 -10.18352      1  \n",
       "..      ...       ...       ...    ...  \n",
       "995  1.4196 -5053.546 -10.75000      0  \n",
       "996  1.6728 -4964.700 -10.35000      0  \n",
       "997  2.6988 -4965.880 -11.01000      1  \n",
       "998  6.1860 -4261.020 -10.18352      0  \n",
       "999  2.5524 -5019.800 -10.18352      0  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data_Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a778188",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "features_mean = Data_Mean.drop('Class', axis=1)\n",
    "predictor_mean = Data_Mean['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dae2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in the dataset \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_mean = StandardScaler()\n",
    "sc_mean.fit(features_mean)\n",
    "fitted_features = sc_mean.fit_transform(features_mean)\n",
    "Data_Mean = pd.DataFrame(features_mean,columns=Data_Mean.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5a5371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test for Mean Value imputation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(fitted_features, predictor_mean, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63656cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=4, random_state=4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the model with decision tree classifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_gini_mean = DecisionTreeClassifier(criterion='gini', max_depth=4, random_state=4)\n",
    "\n",
    "# fitting the builded model the model\n",
    "clf_gini_mean.fit(X_train_mean, y_train_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "545880d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test data\n",
    "y_pred_test_mean = clf_gini_mean.predict(X_test_mean)\n",
    "y_pred_train_mean = clf_gini_mean.predict(X_train_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911e27f",
   "metadata": {},
   "source": [
    "#### Finding Accuracy score using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "836c652c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_Knn=Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0824b1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F9</th>\n",
       "      <th>F10</th>\n",
       "      <th>...</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28703.964</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.051752</td>\n",
       "      <td>-6.99630</td>\n",
       "      <td>1473.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.40510</td>\n",
       "      <td>16004.16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-11645.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.7350</td>\n",
       "      <td>5.9854</td>\n",
       "      <td>14.24730</td>\n",
       "      <td>1.4892</td>\n",
       "      <td>9959.04</td>\n",
       "      <td>-3199.350</td>\n",
       "      <td>6.8670</td>\n",
       "      <td>-4850.820</td>\n",
       "      <td>-11.005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-28726.730</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-5.153000</td>\n",
       "      <td>-4.27404</td>\n",
       "      <td>783.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.54500</td>\n",
       "      <td>16041.48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9759.420</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.1710</td>\n",
       "      <td>4.6222</td>\n",
       "      <td>14.99820</td>\n",
       "      <td>3.1206</td>\n",
       "      <td>10107.44</td>\n",
       "      <td>-3064.950</td>\n",
       "      <td>9.4710</td>\n",
       "      <td>378.780</td>\n",
       "      <td>-9.205</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-28717.120</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-8.440000</td>\n",
       "      <td>-8.25900</td>\n",
       "      <td>2573.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.59962</td>\n",
       "      <td>16422.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10775.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-38.6500</td>\n",
       "      <td>4.4096</td>\n",
       "      <td>17.79000</td>\n",
       "      <td>1.9818</td>\n",
       "      <td>10971.04</td>\n",
       "      <td>-3638.850</td>\n",
       "      <td>2.0373</td>\n",
       "      <td>-5215.480</td>\n",
       "      <td>-10.535</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-81470.290</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.386600</td>\n",
       "      <td>-5.57460</td>\n",
       "      <td>1499.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.56675</td>\n",
       "      <td>16270.04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9416.714</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.6390</td>\n",
       "      <td>8.5080</td>\n",
       "      <td>12.98424</td>\n",
       "      <td>11.5620</td>\n",
       "      <td>9681.10</td>\n",
       "      <td>724.950</td>\n",
       "      <td>2.0220</td>\n",
       "      <td>-4378.420</td>\n",
       "      <td>-9.790</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-28750.800</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.650200</td>\n",
       "      <td>-4.33848</td>\n",
       "      <td>1409.15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.07000</td>\n",
       "      <td>16548.78</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9797.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.7300</td>\n",
       "      <td>5.5188</td>\n",
       "      <td>13.57260</td>\n",
       "      <td>2.5440</td>\n",
       "      <td>10965.64</td>\n",
       "      <td>-2607.150</td>\n",
       "      <td>4.3140</td>\n",
       "      <td>-1919.220</td>\n",
       "      <td>-10.385</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-28685.380</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-4.095060</td>\n",
       "      <td>-15.54300</td>\n",
       "      <td>1654.77</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.09930</td>\n",
       "      <td>16381.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9861.820</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.3800</td>\n",
       "      <td>6.4440</td>\n",
       "      <td>13.15350</td>\n",
       "      <td>3.2538</td>\n",
       "      <td>10170.64</td>\n",
       "      <td>-3932.850</td>\n",
       "      <td>1.4196</td>\n",
       "      <td>-5053.546</td>\n",
       "      <td>-10.750</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-28668.770</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.050914</td>\n",
       "      <td>-9.18600</td>\n",
       "      <td>1457.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.36770</td>\n",
       "      <td>16036.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9418.336</td>\n",
       "      <td>...</td>\n",
       "      <td>-31.7600</td>\n",
       "      <td>4.7966</td>\n",
       "      <td>14.72040</td>\n",
       "      <td>13.4190</td>\n",
       "      <td>9607.28</td>\n",
       "      <td>-3421.860</td>\n",
       "      <td>1.6728</td>\n",
       "      <td>-4964.700</td>\n",
       "      <td>-10.350</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-28667.610</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.887000</td>\n",
       "      <td>-11.41200</td>\n",
       "      <td>1515.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.01500</td>\n",
       "      <td>16097.92</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-10209.620</td>\n",
       "      <td>...</td>\n",
       "      <td>-19.6400</td>\n",
       "      <td>6.4060</td>\n",
       "      <td>13.55100</td>\n",
       "      <td>2.1246</td>\n",
       "      <td>10907.64</td>\n",
       "      <td>-2875.950</td>\n",
       "      <td>2.6988</td>\n",
       "      <td>-4965.880</td>\n",
       "      <td>-11.010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-28750.050</td>\n",
       "      <td>0.73</td>\n",
       "      <td>-5.490800</td>\n",
       "      <td>-5.07480</td>\n",
       "      <td>2249.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.88900</td>\n",
       "      <td>16120.46</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-9358.160</td>\n",
       "      <td>...</td>\n",
       "      <td>-6.4210</td>\n",
       "      <td>4.5810</td>\n",
       "      <td>16.77000</td>\n",
       "      <td>4.0221</td>\n",
       "      <td>9815.54</td>\n",
       "      <td>-3513.039</td>\n",
       "      <td>6.1860</td>\n",
       "      <td>-4261.020</td>\n",
       "      <td>-10.820</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-28700.553</td>\n",
       "      <td>1.73</td>\n",
       "      <td>-4.040009</td>\n",
       "      <td>-5.74200</td>\n",
       "      <td>1752.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.76460</td>\n",
       "      <td>16476.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9690.220</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.3329</td>\n",
       "      <td>4.4034</td>\n",
       "      <td>15.71520</td>\n",
       "      <td>1.6698</td>\n",
       "      <td>9407.24</td>\n",
       "      <td>-3576.120</td>\n",
       "      <td>2.5524</td>\n",
       "      <td>-5019.800</td>\n",
       "      <td>-10.570</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            F1    F2        F3        F4       F5   F6       F7        F8  \\\n",
       "0   -28703.964  0.73 -4.051752  -6.99630  1473.45  0.0  4.40510  16004.16   \n",
       "1   -28726.730  1.73 -5.153000  -4.27404   783.15  0.0  4.54500  16041.48   \n",
       "2   -28717.120  0.73 -8.440000  -8.25900  2573.95  0.0  3.59962  16422.78   \n",
       "3   -81470.290  0.73 -4.386600  -5.57460  1499.68  0.0  3.56675  16270.04   \n",
       "4   -28750.800  1.73 -4.650200  -4.33848  1409.15  1.0  5.07000  16548.78   \n",
       "..         ...   ...       ...       ...      ...  ...      ...       ...   \n",
       "995 -28685.380  0.73 -4.095060 -15.54300  1654.77  1.0  4.09930  16381.38   \n",
       "996 -28668.770  1.73 -4.050914  -9.18600  1457.85  0.0  4.36770  16036.38   \n",
       "997 -28667.610  1.73 -4.887000 -11.41200  1515.96  0.0  5.01500  16097.92   \n",
       "998 -28750.050  0.73 -5.490800  -5.07480  2249.25  0.0  3.88900  16120.46   \n",
       "999 -28700.553  1.73 -4.040009  -5.74200  1752.85  1.0  3.76460  16476.78   \n",
       "\n",
       "      F9        F10  ...      F13     F14       F15      F16       F17  \\\n",
       "0    1.0 -11645.820  ... -13.7350  5.9854  14.24730   1.4892   9959.04   \n",
       "1    1.0  -9759.420  ...  -5.1710  4.6222  14.99820   3.1206  10107.44   \n",
       "2    0.0 -10775.220  ... -38.6500  4.4096  17.79000   1.9818  10971.04   \n",
       "3    1.0  -9416.714  ...  -8.6390  8.5080  12.98424  11.5620   9681.10   \n",
       "4    1.0  -9797.820  ... -14.7300  5.5188  13.57260   2.5440  10965.64   \n",
       "..   ...        ...  ...      ...     ...       ...      ...       ...   \n",
       "995  0.0  -9861.820  ... -19.3800  6.4440  13.15350   3.2538  10170.64   \n",
       "996  0.0  -9418.336  ... -31.7600  4.7966  14.72040  13.4190   9607.28   \n",
       "997  1.0 -10209.620  ... -19.6400  6.4060  13.55100   2.1246  10907.64   \n",
       "998  1.0  -9358.160  ...  -6.4210  4.5810  16.77000   4.0221   9815.54   \n",
       "999  0.0  -9690.220  ...  -4.3329  4.4034  15.71520   1.6698   9407.24   \n",
       "\n",
       "          F18     F19       F20     F21  Class  \n",
       "0   -3199.350  6.8670 -4850.820 -11.005    0.0  \n",
       "1   -3064.950  9.4710   378.780  -9.205    1.0  \n",
       "2   -3638.850  2.0373 -5215.480 -10.535    0.0  \n",
       "3     724.950  2.0220 -4378.420  -9.790    0.0  \n",
       "4   -2607.150  4.3140 -1919.220 -10.385    1.0  \n",
       "..        ...     ...       ...     ...    ...  \n",
       "995 -3932.850  1.4196 -5053.546 -10.750    0.0  \n",
       "996 -3421.860  1.6728 -4964.700 -10.350    0.0  \n",
       "997 -2875.950  2.6988 -4965.880 -11.010    1.0  \n",
       "998 -3513.039  6.1860 -4261.020 -10.820    0.0  \n",
       "999 -3576.120  2.5524 -5019.800 -10.570    0.0  \n",
       "\n",
       "[1000 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNN based imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "Knn_imput = KNNImputer(n_neighbors=2)\n",
    "Data_Knn = pd.DataFrame(Knn_imput.fit_transform(Data_Knn),columns = Data_Knn.columns)\n",
    "Data_Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4ee9d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "features_Knn = Data_Knn.drop('Class', axis=1)\n",
    "predictor_Knn = Data_Knn['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831a1555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_Knn = StandardScaler()\n",
    "sc_Knn.fit(features_Knn)\n",
    "features_Knn = sc_Knn.fit_transform(features_Knn)\n",
    "Data_Knn = pd.DataFrame(features_Knn,columns=Data_Knn.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be6720be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test for Knn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_Knn, X_test_Knn, y_train_Knn, y_test_Knn = train_test_split(features_Knn, predictor_Knn, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bc93684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model building in the decision tree classification\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf_gini_Knn = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=8)\n",
    "\n",
    "# fitting the model\n",
    "clf_gini_Knn.fit(X_train_Knn, y_train_Knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4055b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test and train data \n",
    "y_pred_test_Knn = clf_gini_Knn.predict(X_test_Knn)\n",
    "y_pred_train_Knn = clf_gini_Knn.predict(X_train_Knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c912f9",
   "metadata": {},
   "source": [
    "## KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d74b22c",
   "metadata": {},
   "source": [
    "### Mean Value Based KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a299a3",
   "metadata": {},
   "source": [
    "###### Since the data exploration already done, no need to do the same agin, hence directly applying the algorithm in the KNN based classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f23ea009",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=P2_Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a05f40a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing True and False with 0's and 1's for categorical value conversion through label encoding\n",
    "Data.Class = Data.Class.replace({True: 1, False: 0})\n",
    "Mean_Data=Data.copy()\n",
    "Knn_Data=Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1bf70bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values using mean value imputation\n",
    "Mean_Data['F21'].fillna(Mean_Data['F21'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2daf1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "mean_features = Mean_Data.drop('Class', axis=1)\n",
    "mean_predictor = Mean_Data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "438cd4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "meanSC = StandardScaler()\n",
    "meanSC.fit(features_mean)\n",
    "fitted_features = meanSC.fit_transform(features_mean)\n",
    "Mean_Data = pd.DataFrame(fitted_features,columns=Mean_Data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17f9fb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test for Knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_Mean, X_test_Mean, y_train_Mean, y_test_Mean = train_test_split(fitted_features, mean_predictor, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3aa5e69c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_Mean = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "clf_Mean.fit(X_train_Mean, y_train_Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "14b606e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test and train data\n",
    "y_pred_test_Mean = clf_Mean.predict(X_test_Mean)\n",
    "y_pred_train_Mean = clf_Mean.predict(X_train_Mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e386d2",
   "metadata": {},
   "source": [
    "### KNN Based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9095d2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN based imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "Knnimputer = KNNImputer(n_neighbors=5)\n",
    "Knn_Data = pd.DataFrame(Knnimputer.fit_transform(Knn_Data),columns = Knn_Data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fdee81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "Knn_features = Knn_Data.drop('Class', axis=1)\n",
    "Knn_predictor = Knn_Data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eff3ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "KnnSC = StandardScaler()\n",
    "KnnSC.fit(Knn_features)\n",
    "fittedKnn_features = meanSC.fit_transform(Knn_features)\n",
    "Knn_Data = pd.DataFrame(fittedKnn_features,columns=Knn_Data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26f7f9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test for Knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_Knn, X_test_Knn, y_train_Knn, y_test_Knn = train_test_split(fittedKnn_features, Knn_predictor, test_size = 0.33, random_state = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e9349cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting K-NN to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_Knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "clf_Knn.fit(X_train_Knn, y_train_Knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b0ebba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test and train data\n",
    "y_pred_test_Knn = clf_Knn.predict(X_test_Knn)\n",
    "y_pred_train_Knn = clf_Knn.predict(X_train_Knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f67043d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[147  18]\n",
      " [ 47 118]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix evaluation \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm_mean = confusion_matrix(y_test_mean, y_pred_test_mean)\n",
    "print('Confusion matrix\\n\\n', cm_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f5b411",
   "metadata": {},
   "source": [
    "## SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2298f43b",
   "metadata": {},
   "source": [
    "### Mean Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06775d",
   "metadata": {},
   "source": [
    "###### Since the data exploration already done, no need to do the same agin, hence directly applying the algorithm in the SVM based classification method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "60b8b553",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_Data=Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58ca4906",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputing missing values using mean value imputation\n",
    "SVM_Data['F21'].fillna(SVM_Data['F21'].mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2d913a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "meanSVM_features = SVM_Data.drop('Class', axis=1)\n",
    "meanSVM_predictor = SVM_Data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea65e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "meanSVMSC = StandardScaler()\n",
    "meanSVMSC.fit(meanSVM_features)\n",
    "fitted_featuresSVM = meanSVMSC.fit_transform(meanSVM_features)\n",
    "SVM_Data = pd.DataFrame(fitted_featuresSVM,columns=SVM_Data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d2efd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_MeanSVM, X_test_MeanSVM, y_train_MeanSVM, y_test_MeanSVM = train_test_split(fitted_featuresSVM, meanSVM_predictor, test_size = 0.33, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4fd4da81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(random_state=1)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "SVCMeanClf = SVC(kernel='rbf', random_state = 1)\n",
    "SVCMeanClf.fit(X_train_MeanSVM,y_train_MeanSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d882ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test data\n",
    "y_pred_test_MeanSVM = clf_Mean.predict(X_test_MeanSVM)\n",
    "y_pred_train_MeanSVM = clf_Mean.predict(X_train_MeanSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2ba79",
   "metadata": {},
   "source": [
    "### KNN Based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "49cbbb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMKnn_Data=Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9b3de6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN based imputation in the dataset\n",
    "from sklearn.impute import KNNImputer\n",
    "Knnimputer = KNNImputer(n_neighbors=5)\n",
    "SVMKnn_Data = pd.DataFrame(Knnimputer.fit_transform(SVMKnn_Data),columns = SVMKnn_Data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4c75fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting dependent and independet features separately for testing and training the data\n",
    "KnnSVM_features = SVMKnn_Data.drop('Class', axis=1)\n",
    "KnnSVM_predictor = SVMKnn_Data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3844da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling and Transformation in the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "SVMSC = StandardScaler()\n",
    "SVMSC.fit(KnnSVM_features)\n",
    "fittedKnnSVM_features = SVMSC.fit_transform(Knn_features)\n",
    "SVMKnn_Data = pd.DataFrame(fittedKnnSVM_features,columns=SVMKnn_Data.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2bea74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test for SVM\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_KnnSVM, X_test_KnnSVM, y_train_KnnSVM, y_test_KnnSVM = train_test_split(fittedKnnSVM_features, KnnSVM_predictor, test_size = 0.33, random_state = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72617852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVM to the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf_KnnSVC = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "clf_KnnSVC.fit(X_train_KnnSVM, y_train_KnnSVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d2d8eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the model with test and train data\n",
    "y_pred_test_KnnSVC = clf_Knn.predict(X_test_KnnSVM)\n",
    "y_pred_train_KnnSVC = clf_Knn.predict(X_train_KnnSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cc1cfe",
   "metadata": {},
   "source": [
    "## Accuracy Score Calculation for Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3119c4",
   "metadata": {},
   "source": [
    "###### Performance evaluation is done through different approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c982324",
   "metadata": {},
   "source": [
    "#### Using Mean Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e1e087ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score (Mean Value Imputation): 80.30%\n",
      "Training-set accuracy score (Mean Value Imputation): 85.07%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score for Decision Tree\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "Tree_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_mean, y_pred_test_mean))\n",
    "Tree_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_mean, y_pred_train_mean))\n",
    "print('Test set accuracy score (Mean Value Imputation):', Tree_Test_Accuracy)\n",
    "print('Training-set accuracy score (Mean Value Imputation):',Tree_Train_Accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2d7e89",
   "metadata": {},
   "source": [
    "#### Using KNN Based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e42ecc59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score (KNN Imputation): 65.15%\n",
      "Training-set accuracy score (KNN Imputation): 79.10%\n"
     ]
    }
   ],
   "source": [
    "#Accuracy Score for \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "KNN_Tree_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_Knn, y_pred_test_Knn))\n",
    "KNN_Tree_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_Knn, y_pred_train_Knn))\n",
    "print('Test set accuracy score (KNN Imputation):', KNN_Tree_Test_Accuracy )\n",
    "print('Training-set accuracy score (KNN Imputation):', KNN_Tree_Train_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8b3d4b",
   "metadata": {},
   "source": [
    "## Accuracy Score Calculation for K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c4bba5",
   "metadata": {},
   "source": [
    "#### Using Mean Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00492913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score(Mean Value Imputation): 62.73%\n",
      "Training-set accuracy score (Mean Value Imputation): 78.06%\n"
     ]
    }
   ],
   "source": [
    "#y_test_Mean is the true class labels and y_pred_test_Mean are the predicted class labels in the test-set.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "KNN_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_Mean, y_pred_test_Mean))\n",
    "KNN_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_Mean, y_pred_train_Mean))\n",
    "print('Test set accuracy score(Mean Value Imputation):',KNN_Test_Accuracy )\n",
    "print('Training-set accuracy score (Mean Value Imputation):',KNN_Train_Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908d846c",
   "metadata": {},
   "source": [
    "#### Using KNN based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c112864f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score: (KNN Imputation) 65.15%\n",
      "Training-set accuracy score:(KNN Imputation): 79.10%\n"
     ]
    }
   ],
   "source": [
    "#y_test_Knn is the true class labels and y_pred_test_Knn are the predicted class labels in the test-set.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "KNN_KNN_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_Knn, y_pred_test_Knn))\n",
    "KNN_KNN_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_Knn, y_pred_train_Knn))\n",
    "print('Test set accuracy score: (KNN Imputation)',KNN_KNN_Test_Accuracy )\n",
    "print('Training-set accuracy score:(KNN Imputation):', KNN_KNN_Train_Accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc64b09",
   "metadata": {},
   "source": [
    "## Accuracy Score Calculation for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c700847",
   "metadata": {},
   "source": [
    "#### Using Mean Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbae603a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score (SVM Mean Value Imputation): 73.03%\n",
      "Training-set accuracy score (SVM Mean Value Imputation): 72.99%\n"
     ]
    }
   ],
   "source": [
    "#y_test_MeanSVM is the true class labels and y_pred_test_MeanSVM are the predicted class labels in the test-set.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_MeanSVM, y_pred_test_MeanSVM))\n",
    "SVM_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_MeanSVM, y_pred_train_MeanSVM))\n",
    "print('Test set accuracy score (SVM Mean Value Imputation):', SVM_Test_Accuracy )\n",
    "print('Training-set accuracy score (SVM Mean Value Imputation):', SVM_Train_Accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8dd818",
   "metadata": {},
   "source": [
    "#### Using KNN based Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5844990e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy score (SVM KNN Imputation): 65.15%\n",
      "Training-set accuracy score:(SVM KNN Imputation): 79.10%\n"
     ]
    }
   ],
   "source": [
    "#y_test_KnnSVM is the true class labels and y_pred_test_KnnSVC are the predicted class labels in the test-set.\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "SVM_KNN_Test_Accuracy='{:.2%}'.format(accuracy_score(y_test_KnnSVM, y_pred_test_KnnSVC))\n",
    "SVM_KNN_Train_Accuracy='{:.2%}'.format(accuracy_score(y_train_KnnSVM, y_pred_train_KnnSVC))\n",
    "print('Test set accuracy score (SVM KNN Imputation):', SVM_KNN_Test_Accuracy )\n",
    "print('Training-set accuracy score:(SVM KNN Imputation):', SVM_KNN_Train_Accuracy )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7fcbe33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.89      0.82       165\n",
      "           1       0.87      0.72      0.78       165\n",
      "\n",
      "    accuracy                           0.80       330\n",
      "   macro avg       0.81      0.80      0.80       330\n",
      "weighted avg       0.81      0.80      0.80       330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifiction Report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_mean, y_pred_test_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "335eb84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[147  18]\n",
      " [ 47 118]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix evaluation for decision tree\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm_mean = confusion_matrix(y_test_mean, y_pred_test_mean)\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ef9da474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#COmparison of different imputation methods\n",
    "Mean = [80.30,62.73,73.03]\n",
    "Knn = [65.15,65.15,65.15]\n",
    "index = ['Decision Tree', 'KNN', 'SVM']\n",
    "df = pd.DataFrame({'Mean Value Imputation': Mean,\n",
    "                   'KNN Based Imputation': Knn}, index=index)\n",
    "ax = df.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "247e5d03",
   "metadata": {},
   "source": [
    "# PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b5ac0bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE YOU WILL USE THIS TEMPLATE TO SAVE THE PREDICTIONS ON THE TEST SET\n",
    "\n",
    "# Load the test data\n",
    "test_df = pd.read_csv('P2\\CE802_P2_Test.csv')\n",
    "\n",
    "# Make sure you work on a copy\n",
    "test_data = test_df.iloc[:,:-1].copy()\n",
    "\n",
    "#Imputing the missing values using mean value imputation\n",
    "test_data['F21'].fillna(test_data['F21'].mean(),inplace=True)\n",
    "\n",
    "#Scaling and data transformation\n",
    "test_data=sc_mean.transform(test_data)\n",
    "\n",
    "#Predicting the dependent variable\n",
    "predicted = clf_gini_mean.predict(test_data)\n",
    "\n",
    "# Replace the last (empty) column with your prediction in the orginal data frame\n",
    "test_df.iloc[:,-1] = predicted\n",
    "\n",
    "# Save to the destination file\n",
    "test_df.to_csv('CE802_P2_Test_Predictions.csv', index=False, float_format='%.8g')\n",
    "\n",
    "# IMPORTANT!! Make sure only the last column has changed\n",
    "assert pd.read_csv('P2\\CE802_P2_Test.csv').iloc[:,:-1].equals(pd.read_csv('CE802_P2_Test_Predictions.csv').iloc[:,:-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
